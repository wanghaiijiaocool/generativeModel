{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5113edbc-e1b9-4739-90c8-124b11244e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/generativeModel/disguish_learning/LR_001\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74580f47-898f-4be5-ad3d-92f08e007b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e147e63e-f514-4f24-a9c6-c16a954b7c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('/root/autodl-tmp/generativeModel/disguish_learning/LR_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0f2c1f-5e0d-4fea-b3c5-900f22e04cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import  AutoModelForCausalLM,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e190d5d-f93b-4f7d-b3e3-90f5fab882e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from peft import (\n",
    "    prepare_model_for_int8_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df430052-c69d-433d-aee1-58c81264f3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa117c7-3344-414a-95c9-2a87dc7372e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007940053939819336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 693,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6caf953a384dcba229bd6326c12588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0076313018798828125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 6005243331,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9def4961dc7049dabdb19408c6aaf81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.01G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache_dir = '/root/autodl-tmp/model/'\n",
    "model = AutoModelForCausalLM.from_pretrained('bigscience/bloom-3b',cache_dir=cache_dir,trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom-3b',cache_dir=cache_dir,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265c5ef-00dc-4da4-ab56-1b208e0666f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3a5d6-a8c6-4328-a76a-5999bf9f5fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make model as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee29ed8-5d9b-4211-a53d-cf405d66952e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,#LORA_R,\n",
    "    lora_alpha=16,#LORA_ALPHA,\n",
    "    target_modules=[\"query_key_value\"],#TARGET_MODULES,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model,lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48935299-5ab6-446d-b849-19dd1c00ab6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cache_dir = '/root/autodl-tmp/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f9efb-8763-48c1-bc99-7bf0698374c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"cahya/instructions-zh\",cache_dir=data_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b85007-c9e0-4498-9e59-626c65373bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in data['train']:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5899948-327b-4e84-8bc5-323d0963296f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e28ae-4a17-4293-bebe-bef8b68a5476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_train_example(text:str):\n",
    "    answer_prefix = \"Assistant:\"\n",
    "    prompt_prefix = \"User:\"\n",
    "\n",
    "    answer_start_idx = text.find(answer_prefix)\n",
    "    if(answer_start_idx > 0):\n",
    "        # this is an trian data\n",
    "        answer = text[answer_start_idx + len(answer_prefix):]\n",
    "        prompt = text[:answer_start_idx].replace(prompt_prefix,\"\")\n",
    "    else:\n",
    "        prompt = text\n",
    "        answer = None\n",
    "\n",
    "    return prompt,answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a93d10-a6f6-469d-af48-4dc303c2470b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_tokenzie_func(tokenizer,pad_idx=0,max_length=256,pad=True):\n",
    "    def tokenize(example):\n",
    "        text = example['text']\n",
    "        prompt,answer = split_train_example(text)\n",
    "        prompt_idxs = tokenizer(prompt)\n",
    "        answer_idxs = tokenizer(answer) if answer is not None else []\n",
    "\n",
    "        example = {}\n",
    "        example['input_ids'] = prompt_idxs['input_ids'] + answer_idxs['input_ids']\n",
    "        example['attention_mask'] = prompt_idxs['attention_mask'] + answer_idxs['attention_mask']\n",
    "        example['labels'] = [0] * len(prompt_idxs['attention_mask']) + answer_idxs['input_ids']\n",
    "        example['prompt'] = prompt\n",
    "        example['answer'] = answer\n",
    "        \n",
    "        if(len(example['input_ids']) < max_length):\n",
    "            count = max_length - len(example['input_ids'])\n",
    "            example['input_ids'] = example['input_ids'] + [0] * count\n",
    "            example['attention_mask'] = example['attention_mask']+ [0] * count\n",
    "            example['labels'] = example['labels']+ [0] * count\n",
    "        \n",
    "        example['input_ids'] = example['input_ids'][:max_length]\n",
    "        example['attention_mask'] = example['attention_mask'][:max_length]\n",
    "        example['labels'] = example['labels'][:max_length]\n",
    "        \n",
    "\n",
    "        return example\n",
    "    return tokenize\n",
    "tokenize_func = build_tokenzie_func(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcdf15c-833a-4a0e-adad-a94031cac6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data['train'].map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb3d2b-50c6-41b5-ba5b-518ba76f0b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad189f-3b45-4149-9ceb-288212bb708c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = data['validation'].map(tokenize_func)\n",
    "test_data = data['test'].map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a5b22-ce17-4118-97dd-862be0f32f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddp = True if torch.cuda.device_count() > 1 else False\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=1e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=2000,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=2000,\n",
    "        save_steps=2000,\n",
    "        output_dir=\"lora-alpaca\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        ddp_find_unused_parameters=False if ddp else None,\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
    ").__get__(model, type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ad793-dd06-44e9-ab3b-e1c7fd6b7348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.__version__ >= \"2\":\n",
    "    model = torch.compile(model)\n",
    "\n",
    "##############\n",
    "# 训练循环\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "model.save_pretrained(\"lora-alpaca\")\n",
    "\n",
    "print(\"\\n If there's a warning about missing keys above, please disregard :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da20101-f839-45e9-930c-d88c2b19c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d72512-a7ce-42ef-a66d-4c96a936fa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4080940d-5a1c-43cf-94db-0576a01c7ee1",
   "metadata": {},
   "source": [
    "# 测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445cabb-5ab4-42b6-8504-4fb04cdc728d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"您好\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586b218-61e3-4680-8a2a-418395dad607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_idxs = tokenizer(prompt)\n",
    "\n",
    "prompt_idxs = {\n",
    "    key : torch.LongTensor([prompt_idxs[key][1:-1]]).cuda()\n",
    "    for key in prompt_idxs\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d1262-912b-4578-9559-a3cfaf566cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_idxs['input_ids'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc454163-e53a-4bef-a55f-c8d27ac2cb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_idxs['input_ids'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a001cc-1f0d-4b86-bfff-8083e51c6018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.disable_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3db065-4618-40ac-ae28-9c0c8bb3f32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n,x in model.base_model.model.named_parameters():\n",
    "    if(\"embedding\" in n):\n",
    "        print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2bf03-943d-4108-9390-d5122b67063d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "   x = model.generate(input_ids=prompt_idxs['input_ids'],max_new_tokens=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f20b1-2891-4001-ac12-43c91a5102bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for z in x.cpu().numpy():   \n",
    "    y= tokenizer.decode(z)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94897c6c-efbc-4856-ab89-f379e9c7ce3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
