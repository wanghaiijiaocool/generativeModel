{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94897c6c-efbc-4856-ab89-f379e9c7ce3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/generativeModel/disguish_learning/LR_002\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39418856-7c08-4da8-b91b-6db49753b3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/root/autodl-tmp/generativeModel/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee8bd11-efa6-4b7a-a6e2-a14c439974ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from disguish_learning.models.rm_pair_wise import rm_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0080999-870f-4a80-af53-e1de17ddcc75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /root/miniconda3/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64'), PosixPath('https')}\n",
      "  warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "import torch\n",
    "from peft import (\n",
    "    prepare_model_for_int8_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    ")\n",
    "from datasets import load_dataset,load_from_disk\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec81e9f6-b108-44bf-93dc-01f6ef9feb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_dir = '/root/autodl-tmp/model/'\n",
    "data_cache_dir = '/root/autodl-tmp/data/'\n",
    "##############\n",
    "# 模型部分 THUDM/glm-large-chinese 733m THUDM/glm-10b bigscience/bloom-7b1\n",
    "base_model_name = 'bigscience/bloom-3b'\n",
    "base_model =  AutoModel.from_pretrained(base_model_name,cache_dir=cache_dir)\n",
    "\n",
    "model = rm_pair(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9771d4e-f0d8-4dc5-b99a-ace9c1851e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LORA_WEIGHTS=None#\"/root/autodl-tmp/model/lora-alpaca\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,#LORA_R,\n",
    "    lora_alpha=16,#LORA_ALPHA,\n",
    "    target_modules=[\"query_key_value\"],#TARGET_MODULES,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "model = get_peft_model(model,lora_config)\n",
    "# 最后一层还是要训练的\n",
    "model.base_model.model.scorer.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb0254a-a491-435a-b8db-5c5d14af0742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65cdea1c-ba88-4ff5-9540-e5a4c47e43c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight True\n"
     ]
    }
   ],
   "source": [
    "for name,parameter in model.base_model.model.scorer.named_parameters():\n",
    "    print(name,parameter.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717ae29-02cf-40cc-8467-31fb04893483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3d53af-7b19-4b9a-9056-5deeee95bc59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name,cache_dir=cache_dir,trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d577ce-fbb6-4c4f-82f4-6688355e3265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96295b63-d35a-4776-a3a5-6330e18f346e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f47228-a141-4fbf-87f4-42f6d666fda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cache_dir = '/root/autodl-tmp/data/'\n",
    "dataset_name = \"yitingxie-rlhf-reward-datasets\"\n",
    "dataset = load_from_disk(os.path.join(data_cache_dir,dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756ac6a-40f5-41f9-ab9c-892fbb491705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset['train'][0]['rejected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35298da-45e8-4d82-8e5f-50f24ae8d2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_tokenzie_func(tokenizer, pad_idx=0, max_length=1024, pad=True):\n",
    "    def tokenize(example):\n",
    "        \"\"\"\n",
    "        ignore label idx should always be -100\n",
    "        \"\"\"\n",
    "        prompt_text = example['prompt']\n",
    "        chosen_text = example['chosen']\n",
    "        rejected_text = example['rejected']\n",
    "        \n",
    "        prompt_idxs = tokenizer(prompt_text)\n",
    "        chosen_idxs = tokenizer(chosen_text)\n",
    "        rejected_idxs = tokenizer(rejected_text)\n",
    "        \n",
    "        # positive\n",
    "        positive = prompt_idxs['input_ids']  + chosen_idxs['input_ids'] \n",
    "        att_mask_pos = prompt_idxs['attention_mask']  + chosen_idxs['attention_mask'] \n",
    "        # negtive\n",
    "        negtive = prompt_idxs['input_ids']  + rejected_idxs['input_ids'] \n",
    "        att_mask_neg = prompt_idxs['attention_mask']  + rejected_idxs['attention_mask'] \n",
    "        \n",
    "        pos_actual_len = len(positive)\n",
    "        neg_actual_len = len(negtive)\n",
    "        # pad and truck\n",
    "        positive = positive + [tokenizer.pad_token_id] * max(0,max_length - len(positive))\n",
    "        att_mask_pos = att_mask_pos + [0] * max(0,max_length - len(att_mask_pos) )\n",
    "        negtive = negtive + [tokenizer.pad_token_id] * max(0,max_length - len(negtive))\n",
    "        att_mask_neg = att_mask_neg + [0] * max(0,max_length - len(att_mask_neg))\n",
    "        positive = positive[:max_length]\n",
    "        att_mask_pos = att_mask_pos[:max_length]\n",
    "        negtive = negtive[:max_length]\n",
    "        att_mask_neg = att_mask_neg[:max_length]\n",
    "        \n",
    "        \n",
    "        example['pos_actual_len'] = pos_actual_len\n",
    "        example['neg_actual_len'] = neg_actual_len\n",
    "        \n",
    "        example['positive'] = positive\n",
    "        example['negtive'] = negtive\n",
    "        \n",
    "        #example['prompt_idxs'] = prompt_idxs\n",
    "        example['att_mask_pos'] = att_mask_pos\n",
    "        example['att_mask_neg'] = att_mask_neg\n",
    "        #example['chosen_idxs'] = chosen_idxs\n",
    "        #example['rejected_idxs'] = rejected_idxs\n",
    "        \n",
    "        \n",
    "        \n",
    "        return example\n",
    "\n",
    "    return tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c6040-9df4-4b93-a191-60c42be86995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15bf68-4815-49f3-8d47-72f1063b6de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenize_func = build_tokenzie_func(tokenizer,max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c3663-0992-4a00-8d77-f99397fdbff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = dataset['train'].map(tokenize_func)\n",
    "test_data = dataset['test'].map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f060874-b6ff-4863-b7fc-e5cc72bad6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984253e-778d-4b68-8cc0-4c71caef5cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data._data.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc4bd0-fddf-41de-8759-aa26c54f835f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda52076-22e4-4e1b-85e8-e8f4466b8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "\n",
    "class data_collator_self(DataCollatorMixin):\n",
    "    return_tensors: str = \"pt\"\n",
    "    \n",
    "    def batch_tensor_stack(self,features):\n",
    "        assert len(features) > 0\n",
    "        #print(features)\n",
    "        batch = { \n",
    "            k : [v]\n",
    "            for k,v in features[0].items()\n",
    "        }\n",
    "        #print(batch)\n",
    "        \n",
    "        for fea in features[1:]:\n",
    "            #print(\"-\"*100)\n",
    "            #print(fea)\n",
    "            for k,v in fea.items():\n",
    "                batch[k].append(v)\n",
    "        \n",
    "        for k in batch:\n",
    "            try:\n",
    "                batch[k] = torch.tensor(batch[k],dtype=torch.long)\n",
    "            except Exception as e:\n",
    "                #print(k,e)\n",
    "                batch[k] = batch[k]\n",
    "        #print(\"-\"*100)\n",
    "        #print(batch)\n",
    "        return batch\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def torch_call(self, features):\n",
    "        import torch\n",
    "        #print(\"--\"*100)\n",
    "        #print(features)\n",
    "        \n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature[label_name] for feature in features] if label_name in features[0].keys() else None\n",
    "\n",
    "        no_labels_features = self.batch_tensor_stack(features)#[{k: v for k, v in feature.items() if k != label_name} for feature in features]\n",
    "\n",
    "\n",
    "        \n",
    "        batch = no_labels_features\n",
    "        #print(\"-\"*100)\n",
    "        #print(batch)\n",
    "        #print(\"-\"*100)\n",
    "        if labels is None:\n",
    "            return batch\n",
    "\n",
    "        batch[label_name] = torch.tensor(batch[label_name], dtype=torch.int64)\n",
    "        #print(batch)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5d419-7cf0-42c0-9a29-df578504de9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddp = True if torch.cuda.device_count() > 1 else False\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=train_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        remove_unused_columns=False,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=128 // 1,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=1e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        save_steps=200,\n",
    "        output_dir=\"lora-alpaca\",\n",
    "        save_total_limit=3,\n",
    "        max_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        ddp_find_unused_parameters=False if ddp else None,\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_self()#transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.base_model.config.use_cache = False\n",
    "\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
    ").__get__(model, type(model))\n",
    "if torch.__version__ >= \"2\":\n",
    "    model = torch.compile(model)\n",
    "\n",
    "##############\n",
    "# 训练循环\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "save_path = cache_dir + \"/lora-alpaca/reward_model\"\n",
    "model.disable_adapter()\n",
    "model.save_pretrained(save_path)\n",
    "torch.save(model.get_base_model(),os.path.join(save_path,'model.bin'))\n",
    "\n",
    "print(\"\\n If there's a warning about missing keys above, please disregard :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20783e1-6e30-4d7b-8e7e-13aa03c220a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2881582-4653-48c7-a2ca-d69a88575bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269d552-34a9-4098-8370-0cc0d0a66c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68e029-66fd-4563-bd2e-69f768887306",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36f907-f217-4679-b3c8-15cdf420733e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c8851-978f-478b-9a2a-445033e221df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
